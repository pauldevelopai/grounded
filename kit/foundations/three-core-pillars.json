{
  "slug": "three-core-pillars",
  "title": "Three Core Pillars of the Curriculum",
  "content": "## 1) Sovereignty\nWhenever possible, use tools that keep data on the journalist's own device. The important note to keep in the back of your head at all times is that using AI can always results in a security risk and that is why when deciding to use AI it isn't just a decision to improve efficiency, but also a decision that takes security into account. AI sovereignty is about allowing the media to control its own data pipelines, train and operate its own AI models that reflect local context, build their own tools and run them on their own infrastructure. They need this to save money, to make money and also to not get swallowed by companies that don't have their best interests at heart. It is a way for countries or communities to operate without global reliance on big tech. For our purposes it is always better to teach the commercial tool alongside the technical alternative. This demystifies the \"magic\" of AI and provides a free, secure backup for students with limited resources or high security needs. Commercial tools change pricing, alter privacy policies, or get banned. By teaching students the \"harder,\" technical route, you give them a skill that is free, secure, and permanent. This is vital for investigative journalists handling sensitive leaks in hostile information environments.\n## 2) Time Reinvestment\nAI saves time. But in journalism, saving time is dangerous if that time is treated as leisure. This toolkit introduces the concept of the \"Time Dividend.\" The Rule: If an AI tool saves you 4 hours of transcribing, you owe the story 4 hours of deeper human work. The key to saving time with AI is also figuring out how to use that time to make the piece of work better. What you should do with this extra time isn't always obvious. And arguably it needs to be on tasks that can in no way be automated, like interviewing one more source. The goal of saving time with AI is to spend more time on human connection and investigation.\n## 3) Balance\nTo make it easier to compare AI tools in a newsroom or teaching context, this toolkit introduces a simple, original rating system called the CDI score. The CDI score was created specifically for this guide to help lecturers and students quickly assess whether a tool is practical, accessible, and appropriate for their environment.\nRather than ranking tools as \"good\" or \"bad,\" the CDI score highlights barriers to entry. It asks three questions every newsroom should consider before adopting an AI tool: Can we afford it? Can we use it? And what does it cost us in terms of privacy and control?"
}